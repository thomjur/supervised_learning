{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369b2763",
   "metadata": {},
   "source": [
    "# Machine Learning 1: Supervised Learning (13.06.2023)\n",
    "by Thomas Jurczyk (Dr. Eberle Zentrum, Universität Tübingen)\n",
    "\n",
    "Version: 0.2 (27.03.2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da396f4",
   "metadata": {},
   "source": [
    "In this section of the course, we will delve into the subject of the fundamental principles and techniques of machine learning. While we will only scratch the surface of this vast field, we will learn how to train and apply basic machine learning models in Python.\n",
    "\n",
    "But before we start, let's define what machine learning is.\n",
    "\n",
    "> Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. (Arthur Samuel, 1959)\n",
    "\n",
    "The above statement is a reference to a quote from the book *Hands-On Machine Learning with Scikit-Learn and TensorFlow* by Aurelien Géron (ISBN: 1491962291), a highly recommended resource for those seeking to learn more about machine learning with Python from an applied perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796351b0",
   "metadata": {},
   "source": [
    "The field of machine learning is categorized into three main areas:\n",
    "\n",
    "1. **Supervised learning**\n",
    "2. **Unsupervised learning**\n",
    "3. **Reinforcement learning**\n",
    "\n",
    "In this course, we will concentrate on two of these areas, namely **supervised learning** and **unsupervised learning** (the latter being the subject of the following session)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644db44",
   "metadata": {},
   "source": [
    "# What is supervised learning?\n",
    "Supervised learning involves training a machine learning model using a dataset that already contains the desired labels to be predicted. This type of learning is commonly used for **classification** tasks, which can be binary (e.g., \"spam\" or \"not spam\" for emails) or multi-class (e.g., \"low,\" \"medium,\" and \"high\" for the creditworthiness of a person). If the aim is to predict continuous labels such as housing prices, the process is referred to as **regression**.\n",
    "\n",
    "For example, suppose we want to analyze Twitter data related to \"climate change\" and train a machine learning model to predict whether a tweet expresses a critical/affirmative stance towards climate change or a negative/neglecting one. We assume that we already have a previously annotated data set with exemplary tweets which either accept or ignore/downplay climate change, which means that we are confronted with a task situated in the field of supervised learning. In this case, the data we use to train our supervised learning algorithm will contain information like:\n",
    "\n",
    "| tweet | label |\n",
    "|:------|:------|\n",
    "|Climate change is dangerous and we need to stop it!|1|\n",
    "|The measures against climate change are nonsense. We need to leave the Paris agreement RIGHT NOW!|0|\n",
    "|I am REALLY desperate. It's getting warmer and warmer every winter...|1|\n",
    "|....|...|\n",
    "\n",
    "In this table, the label `1` denotes a critical/affirmative stance towards climate change, whereas `0` indicates a negative/neglecting one.\n",
    "\n",
    "The initial step is to provide this data, separated into features (`tweet`) and labels (`label`), to our machine learning algorithm. The algorithm will then learn how to predict the correct label based on the input feature (which, in our example, is just text). The approach used by the algorithm to accomplish this depends on the specific learning algorithm, with various techniques suited to different types of data and tasks.\n",
    "\n",
    "Once our model has been trained on our training dataset, it will provide us with an estimate of how successful the classification is. The most fundamental measure for this is **accuracy**, which indicates the percentage of true positives (i.e., critical tweets) and true negatives (negative/neglecting tweets):\n",
    "\n",
    "$\\frac{T_P + T_N}{N}$\n",
    "\n",
    "Although accuracy can be a suitable means of assessing the performance of our classifier, it is generally advisable to utilize other metrics as well. This is particularly crucial if our label distribution is biased. For instance, if we have a dataset with 100 entries, of which 99 are labeled \"1\" and only one is labeled \"0,\" predicting \"1\" for every entry would result in an accuracy of 99%! However, a model that always predicts \"1\" is essentially useless.\n",
    "\n",
    "As a result, it is often recommended to employ additional scores instead. For instance, to assess the performance of a (binary) classifier, a confusion matrix can be used.\n",
    "\n",
    "## Confusion matrix\n",
    "\n",
    "Suppose our dataset comprises 23 positive cases (labeled \"1\") and 18 negative cases (labeled \"0\"). Our machine learning classifier classifies 19 of the 23 positive cases as \"1\" (true positives) and 10 of the 18 negative cases as \"0\" (true negatives), resulting in an accuracy of approximately 70%.\n",
    "\n",
    "Our confusion matrix would then look like this (EP: estimated positives, EN: estimated negatives):\n",
    "\n",
    "||**P**|**N**|\n",
    "|:--:|:---:|:----:|\n",
    "|**EP**|19|8|\n",
    "|**EN**|4|10|\n",
    "\n",
    "These values can be used to compute various estimators of our machine learning model's performance, with two popular metrics being **precision** and **recall**.\n",
    "\n",
    "### Precision\n",
    "\n",
    "How accurate is the estimated number of positive cases?\n",
    "\n",
    "$\\frac{T_P}{T_P+F_P}$\n",
    "\n",
    "$\\frac{19}{19+8}=0.7$\n",
    "\n",
    "(For the negative cases: $\\frac{10}{10+4}=0.71$)\n",
    "\n",
    "### Recall\n",
    "\n",
    "How many positive cases have been identified?\n",
    "\n",
    "$\\frac{T_P}{T_P+F_N}$\n",
    "\n",
    "$\\frac{19}{19+4}=0.83$\n",
    "\n",
    "(For the negative cases: $\\frac{10}{10+8}=0.55$)\n",
    "\n",
    "### F<sub>1</sub> score\n",
    "\n",
    "Both precision and recall are often combined in a single number, the so-called F<sub>1</sub> score.\n",
    "\n",
    "$\\frac{2*Precision*Recall}{Precision+Recall}$\n",
    "\n",
    "$\\frac{2*0.7*0.83}{0.7+0.83}=0.76$\n",
    "\n",
    "(For the negative cases: $\\frac{2*0.7*0.55}{0.7+0.55}=0.56$)\n",
    "\n",
    "## Train/Test sets\n",
    "Another prevalent approach is to partition the labeled training dataset into two distinct sets: the train and test sets. The training set, as the name implies, is utilized to train the classifier, while the test set is only used in the final stages of the training process to assess how well the model performs on unfamiliar data. If the model performs exceptionally well on the training set but poorly on the test set, this can indicate **overfitting**, implying that the model is unable to generalize from the data it has been trained on.\n",
    "\n",
    "It is typical to divide the dataset into **75%** (or 80%) for training and **25%** (or 20%) for testing. Note: Be sure to use stratified sampling to avoid the worst-case scenario of having all positive labels in the test set and all negative labels in the training set.\n",
    "\n",
    "## Different types of (supervised) machine learning algorithms\n",
    "\n",
    "There are numerous machine learning algorithms available, and it is often recommended to train multiple models on the same dataset and compare their performance to determine the best one.\n",
    "\n",
    "There is no one-size-fits-all approach to determining which algorithm to use, as the optimal machine learning algorithm for text classification will be influenced by several factors, including the amount and quality of training data, the complexity of the classification task, and the available computational resources. Some popular algorithms for text classification include **support vector machines**, **decision trees**, and **random forests** (or **recurrent neural networks** in the context of deep learning). Generally, it is a good idea to experiment with several algorithms and compare their performance to identify the best one for your specific use case (or to use all of them and take a majority vote for the final prediction, which is known as ensemble learning).\n",
    "\n",
    "In our example, we will employ random forests for text classification.\n",
    "\n",
    "## Random forests\n",
    "\n",
    "Random forests are a type of ensemble learning algorithm, which means that they use a collection of individual \"decision trees\" to make predictions. Each tree in the random forest is a decision tree, which makes predictions based on the features of the input data. A decision tree is a tree-like model in which each internal node represents a feature, each branch represents a decision based on that feature, and each leaf node represents a prediction.\n",
    "\n",
    "![Example of a single decision tree of the survival of passengers from the Titanic (Source: Wikipedia).](Decision_Tree.jpg)\n",
    "\n",
    "To make a prediction using a random forest classifier, the algorithm first splits the input data into multiple subsets and trains a decision tree on each subset. This is known as bootstrapping, and it helps to reduce overfitting and improve the overall performance of the model. Then, the predictions made by each individual tree are combined using a majority vote or another ensemble method to produce the final prediction. This combination of predictions helps to reduce the variance and improve the accuracy of the model.\n",
    "\n",
    "## K-Nearest Neighbors\n",
    "\n",
    "Another popular machine learning algorithm for classification tasks is k-nearest neighbors (short: knn).\n",
    "\n",
    "> An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor. (Source: [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm))\n",
    "\n",
    "![Diagram for KNN (source: sciencenet.cn).](knn.png)\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "We won't go into the details of how these machine learning algorithms work (for instance, how the decision tree algorithm decides which feature in the first node etc.). If you want to know more in this regard, please consult the literature or the corresponding documentations. There are numerous machine learning algorithms available, and we have only introduced two that are considered basic and easy to understand. Generally, it is advisable to train multiple models and compare their performance. In the upcoming sections of this notebook, we will employ scikit-learn to apply machine learning, and the good news is that the overall process of training a model with scikit-learn is quite similar regardless of which algorithm we choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494b7b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926e064",
   "metadata": {},
   "source": [
    "# Training a machine learning model with scikit-learn\n",
    "\n",
    "## Loading data\n",
    "In this example, we will once more work with the Twitter data that we've already cleaned and transformed in the previous notebooks. Even though handling textual data demands some special treatment, the overall procedure is pretty similar for other data types, too.\n",
    "\n",
    "Before we can start with the actual training part, we first need to load our previously cleaned and transformed data set into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307ecd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02091240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the path to the HDF storage here\n",
    "store = pd.HDFStore(\"ds_store_2023.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0194bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = store[\"df_annotated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53361c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10284 entries, 0 to 10283\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count  Dtype              \n",
      "---  ------                        --------------  -----              \n",
      " 0   text                          10284 non-null  object             \n",
      " 1   author_id                     10284 non-null  object             \n",
      " 2   id                            10284 non-null  object             \n",
      " 3   created_at                    10284 non-null  object             \n",
      " 4   public_metrics.retweet_count  10284 non-null  int64              \n",
      " 5   public_metrics.reply_count    10284 non-null  int64              \n",
      " 6   public_metrics.like_count     10284 non-null  int64              \n",
      " 7   public_metrics.quote_count    10284 non-null  int64              \n",
      " 8   url.count                     10284 non-null  int64              \n",
      " 9   url.list                      5037 non-null   object             \n",
      " 10  hashtag.count                 10284 non-null  int64              \n",
      " 11  hashtag.list                  2194 non-null   object             \n",
      " 12  annotation.count              10284 non-null  int64              \n",
      " 13  annotation.list               3463 non-null   object             \n",
      " 14  attachments                   10284 non-null  int64              \n",
      " 15  date                          10284 non-null  datetime64[ns, UTC]\n",
      " 16  clean_text                    10284 non-null  object             \n",
      " 17  annotation                    10284 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(9), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e9050",
   "metadata": {},
   "source": [
    "## Data annotation\n",
    "Remember that we want to apply a supervised learning approach. Consequently, we must label our data or acquire existing labels that we aim to predict.\n",
    "\n",
    "As an exemplary task, our objective of the machine learning component of this analysis is to develop a classifier capable of **categorizing tweets as either \"positive\" (= accepting) or \"negative\" (= neglecting/downplaying) towards climate change and its effects**.\n",
    "\n",
    "At present, we lack these labels, implying that we must first annotate our data. Although this may seem \"trivial,\" the data annotation process is frequently more intricate than one might anticipate and necessitates specialized expertise. However, since our focus in this seminar is on the methods, we will keep things as straightforward as possible.\n",
    "\n",
    "To annotate our data, we will create a function that enables us to manually classify each tweet as \"1\" (positive/neutral) or \"0\" (negative/neglecting). To start training our machine learning classifier, I suggest that we annotate at least several hundred tweets (yet, the more the better), which is something that I have already done in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b551f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def annotate(df: pd.DataFrame, storage_path: str=\"../5_Cleaning_Transformation/\") -> pd.DataFrame:\n",
    "    '''Function to annotate texts in a column of a DataFrame. Needs an existing column \"annotation\".\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "            df: pd.DataFrame\n",
    "                The DataFrame that includes a \"text\" column and a column \"annotation\".\n",
    "                \n",
    "            storage_path: str\n",
    "                Path where HDF storage is found to save data during annotation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            The DataFrame with the (partial) annotation.\n",
    "    '''\n",
    "    if \"text\" and \"annotation\" not in df.columns:\n",
    "        print(\"Please pass a DataFrame including 'text' and 'annotation' columns.\")\n",
    "    \n",
    "    try:\n",
    "        store = pd.HDFStore(storage_path+\"store.h5\")\n",
    "    except:\n",
    "        print(\"Storage not found, abort.\")\n",
    "        return df\n",
    "    \n",
    "    # annotation loop\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        continue_ = False\n",
    "        if df.loc[i, \"annotation\"] == -1:\n",
    "            while not continue_:\n",
    "                print(df.loc[i,\"text\"])\n",
    "                print()\n",
    "                time.sleep(0.2)\n",
    "                annotation = input(\"Please pass annotation (1/0): \")\n",
    "                confirm = input(f\"Confirm {annotation}? (y/n)\")\n",
    "                if confirm.lower() == \"y\":\n",
    "                    if annotation == \"1\":\n",
    "                        df.loc[i, \"annotation\"] = int(annotation)\n",
    "                        continue_ = True\n",
    "                    elif annotation == \"0\":\n",
    "                        df.loc[i, \"annotation\"] = int(annotation)\n",
    "                        continue_ = True\n",
    "                    else:\n",
    "                        print(\"Wrong annotation input, please redo!\")\n",
    "                        time.sleep()\n",
    "                    clear_output()\n",
    "            end = input(\"End annotations and save dataframe? (y/n)? \")\n",
    "            if end.lower() == \"y\":\n",
    "                    store[\"df_annotated\"] = df\n",
    "                    store.close()\n",
    "                    return df\n",
    "            clear_output()\n",
    "        \n",
    "    store[\"df_annotated\"] = df\n",
    "    store.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotating tweets (not necessary here)\n",
    "#df = annotate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2f0861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 601 tweets annotated!\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are currently {len(df[df['annotation'] != -1])} tweets annotated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43eec6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.55% of the data are labeled 1.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(len(df[df['annotation'] == 1]) / len(df[df['annotation'] != -1])) * 100:.2f}% of the data are labeled 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc29a6",
   "metadata": {},
   "source": [
    "## Tf-idf transformation using scikit-learn\n",
    "The first thing we need to do is to enable our machine learning model to work with text. To do so, we will convert each text/tweet (often called \"documents\" in a machine learning context) into a vector in which each dimension represents a word in the vocabulary of all documents. We will only explain some details of this approach. If you want to know more, I recommend the [tutorial by Melanie Walsh](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html).\n",
    "\n",
    "Let's assume we have two short texts:\n",
    "\n",
    "> we all live in a submarine\n",
    "\n",
    "> we live in a yellow submarine\n",
    "\n",
    "First, we create a vocabulary of these two sentences where each word has an index (the key in the dictionary):\n",
    "\n",
    "`{0: \"we\", 1: \"live\", 2: \"a\", 3: \"submarine\", 4: \"in\", 5: \"yellow\", 6: \"all\"}`\n",
    "\n",
    "Based on this vocabulary, we create a vector of each sentence using a Python list (or numpy array). In this list, the position/index is related to the word in the vocabulary dictionary with the corresponding key, and the numbers in the list at each position represents the frequency of the corresponding words in the sentence (which is always 1 or 0 in our example). For instance, the first position in the following lists `v1` and `v2` is related to the word `we`, which has the key `0` in the vocabulary/dictionary (and position `0` in the list). It appears only once in both sentences, so the value is `1`. \n",
    "\n",
    "v1: `[1, 1, 1, 1, 1, 0, 1]`\n",
    "\n",
    "v2: `[1, 1, 1, 1, 1, 1, 0]`\n",
    "\n",
    "You can create such document vectors with the absolute frequencies of each word per document using scikit-learn's `CountVectorizer()` class. We can now use these vectors to calculate the distance between both vectors, for instance using **Euclidean distance** (or other metrics, such as Manhattan distance):\n",
    "\n",
    "$\\sqrt{(v_{10}-v_{20})^2+(v_{11}-v_{21})^2+...+(v_{16}-v_{26})^2}$\n",
    "\n",
    "Which is $\\sqrt{2}$ in our example. Since Euclidean distance can become problematic in high dimensional spaces (the so-called *curse of dimensionality*), you might want to apply **cosine similarity** instead. And tf-idf transformed vectors can be very long, depending on the size of the vocabulary, and mostly consist of 0s and only very few other numbers (so-called *sparse vectors*).\n",
    "\n",
    "### Cosine similarity\n",
    "\n",
    "cosine similarity = $\\frac{\\vec{A} \\cdot \\vec{B}}{||\\vec{A}|| \\cdot ||\\vec{B}||}$\n",
    "\n",
    "This formula represents the cosine similarity between two vectors, A and B. The dot product of the vectors is represented by the symbol \"·\", and the magnitude of a vector is represented by the double vertical bars \"||\". Cosine similarity can take a value between -1 and 1 (-1: vectors point into opposite directions (= have an opposite meaning), 1: vectors point into the same direction (= have a similar meaning)).\n",
    "\n",
    "In our example, the cosine similarity is:\n",
    "\n",
    "$\\vec{A} \\cdot \\vec{B} = 1+1+1+1+1=5$\n",
    "\n",
    "$||\\vec{A}|| \\cdot ||\\vec{B}||=\\sqrt{6} \\cdot \\sqrt{6}= 6$ \n",
    "\n",
    "$\\frac{\\vec{A} \\cdot \\vec{B}}{||\\vec{A}|| \\cdot ||\\vec{B}||}= \\frac{5}{6}= 0.83$\n",
    "\n",
    "\n",
    "### But what is Tf-idf?\n",
    "\n",
    "Tf-idf stands for *term frequency - inverted document frequency* and is a measure to underline the importance of a word/term regarding its ability to distinguish documents from each other. For instance, a term such as \"the\" appears in almost every sentence is thus of no value for our calculations. Tf-idf helps us to get rid of these terms or make them less important for the similarity calculations (for instance, when using cosine similarity).\n",
    "\n",
    "**tf-idf = term_frequency \\* inverted_document_frequency**\n",
    "\n",
    "term_frequency = number of times a given term appears in document\n",
    "\n",
    "inverse_document_frequency = log(total number of documents / number of documents with term) + 1\n",
    "\n",
    "Transforming our two vectors via tf-idf leads to the following results (assuming we take the logarithm of 2):\n",
    "\n",
    "v1 = `[1, 1, 1, 1, 1, 0, 2]`\n",
    "\n",
    "v2 = `[1, 1, 1, 1, 1, 2, 0]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044b52a",
   "metadata": {},
   "source": [
    "## Implementing tf-idf using scikit-learn\n",
    "Implementing tf-idf transformation with scikit-learn is very easy. We can use the `TfidfVectorizer()` class from the `feature_extraction.text` module (which is a comination of sklearn's `CountVectorizer()` and `TfidfTransformer()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8dcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd72c6",
   "metadata": {},
   "source": [
    "Next, we extract the features (`clean_text`) and the labels we want to predict (`annotation`) from our DataFrame. These will be used as the training data for our machine learning algorithm. By convention, the feature vectors are stored in variable called `X` and the labels in `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1d5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text data and labels\n",
    "\n",
    "X = df.loc[df[\"annotation\"] != -1, \"clean_text\"]\n",
    "y = df.loc[df[\"annotation\"] != -1, \"annotation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab996f0b",
   "metadata": {},
   "source": [
    "In the subsequent phase, we instantiate our `TfidfVectorizer()` and convert our `X` data using tf-idf. We use the `fit_transform()` method, which is commonly utilized in the context of other sklearn models. It combines `fit()` (which trains the model based on the input data; in this case, training involves creating a vocabulary) and `transform()` (which transforms our input data and returns the modified data, implying it generates the document vectors for each `clean_text`). It's worth noting that we are already passing numerous arguments to the `TfidfVectorizer()` class, which is not required (we will discuss the different parameters shortly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b356fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=2, max_features=1000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f28b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50b1d5",
   "metadata": {},
   "source": [
    "We can check the results of the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40335d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the shape of the documents\n",
    "# note that most entries are zero\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a78f8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef5c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05080766, 0.2807065 , 0.09960407, 0.05157635, 0.24835331,\n",
       "       0.42100499, 0.1677339 , 0.49670661, 0.2190125 , 0.2617811 ,\n",
       "       0.2702911 , 0.29413429, 0.24835331, 0.23348923])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the tf-idf values of the existing entries\n",
    "X[1].toarray()[X[1].toarray() != 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2bbab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['climate crisis', 'change problem', 'rate climate', 'make',\n",
       "        'medium', 'push', 'scam', 'crisis', 'problem', 'rate', 'yes',\n",
       "        'climate change', 'change', 'climate'], dtype='<U20')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the words/n-grams represented in this vector\n",
    "vectorizer.inverse_transform(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34752fc",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "As previously explained, it is common practice to split the data into a train and test set. We will separate the data set into 80% training and 20% test data using sklearn's `train_test_split()` function (that applies stratified sampling by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4b4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3050e8",
   "metadata": {},
   "source": [
    "## Training a random forest classifier\n",
    "Finally, we can train our machine learning model (a random forest) using the previously annotated and tf-idf transformed data. As you can see, training the model only takes three lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb51514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0757d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd38d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839db810",
   "metadata": {},
   "source": [
    "Let us check the quality of our model by predicting the data in our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2664b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63720862",
   "metadata": {},
   "source": [
    "This seems to be a reasonable initial attempt and is substantially better than random guessing. However, we should bear in mind that we are interested in accurately predicting both labels since we want to analyze both the positive and negative tweets. As a result, we should also evaluate the precision, recall, f1 scores, and the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc88dd",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8961aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make predictions on the test set\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# create a confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42ef0812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fcc80cb5fa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=rf.classes_)\n",
    "\n",
    "plot_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2e2c5",
   "metadata": {},
   "source": [
    "This looks pretty underwhelming since most of our data has been labeled as 1! Let's check the precision, recall, and f1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f746034",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F<sub>1</sub> scores for the \"1\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a18d4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bac31a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9fb9f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9069767441860465"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be7466fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8297872340425532"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a3cd8",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F<sub>1</sub> scores for the \"0\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9ecece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "701afd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3142857142857143"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d38fcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40740740740740744"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c95017",
   "metadata": {},
   "source": [
    "As we can see, the results for our negative label are horrible, and we should certainly do something about this. Because in its current state, our classifier is pretty useless.\n",
    "\n",
    "### How can we improve the performance of our machine learning model?\n",
    "\n",
    "1. Initially, we should **annotate more data** while paying attention to the annotation quality, such as ambiguous cases or incorrect annotations. Working in teams can also be beneficial. Additionally, we should reconsider binary classification: is it sensible in light of the data? Or should we include additional classes for more refined annotations?\n",
    "2. We can explore alternative machine learning algorithms. Perhaps random forests are unsuitable, and we should consider k-nearest neighbors or a naive Bayesian classifier?\n",
    "3. We can employ cross-validation to gain a better understanding of how our model performs when trained on various combinations of our training set.\n",
    "4. We could begin with hyper-parameter tuning. This entails testing various values for both the vectorizer and the ML algorithm while constructing/training our `TfidfVectorizer()` and `RandomForests()` model. We will accomplish this using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), which is a relatively advanced technique, but it is also feasible to manually experiment with different combinations of arguments passed to the individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39f74f",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Cross-validation is a resampling procedure used to evaluate the performance of machine learning models. It works by dividing the data into a number of folds (also called splits), and then training the model on one fold and evaluating it on the remaining folds. This process is repeated for each fold, and the model is trained and evaluated multiple times. The final performance metric is then calculated as the average performance across all folds.\n",
    "\n",
    "![Source: https://scikit-learn.org/stable/_images/grid_search_cross_validation.png](grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate the classifier using cross-validation\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the average accuracy and standard deviation\n",
    "print(f\"Accuracy: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a69f1",
   "metadata": {},
   "source": [
    "## *Advanced*: Hyper-Parameter tuning (random forests)\n",
    "Please note that you can do the following steps also manually by just trying different arguments. In this part, we will systematically try out different combinations of arguments in order to find the combination that leads to the best performing classifier. To do so, we will create a **pipeline** first that includes our vectorizer and the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9965adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9d48d",
   "metadata": {},
   "source": [
    "First, we need to renew our `X` and `y` data, because we have decided to work with a pipeline that accepts pure texts (our current `X` variable refers to the tf-idf transformed document vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "870bf91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = store[\"df_annotated\"]\n",
    "df = df[df[\"annotation\"] != -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"clean_text\"].to_numpy(), df[\"annotation\"].to_numpy(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6485aa",
   "metadata": {},
   "source": [
    "Next, we create a pipeline. The advantage of using a pipeline is that we can now directly pass texts to our pipeline, which are first tf-idf transformed and then forwarded as vectors to our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "643033a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = make_pipeline(TfidfVectorizer(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67e242",
   "metadata": {},
   "source": [
    "For the GridSearch, we define a dictionary with all arguments that we would like to try when training our classifier (and when using the `TfidfVectorizer()`). **Important:** This can take a pretty long time, since there are 3 x 3 x 3 x 2 x 3 x 3 x 3 = 1.458 combinations here!\n",
    "\n",
    "Also note that we are using \"balanced_accurary\" as a scoring measure instead of \"accuracy\" because we are interested in a precise labeling of both labels (not only the positive ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f618f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'tfidfvectorizer__max_df': [1.0, 0.5, 0.25],\n",
    "    'tfidfvectorizer__max_features': [None, 500, 1000],\n",
    "    'tfidfvectorizer__ngram_range': [(1, 1), (1,2), (1,3)],\n",
    "    'tfidfvectorizer__stop_words': [None, 'english'],\n",
    "    'tfidfvectorizer__min_df': [1,2,3],\n",
    "    'randomforestclassifier__min_samples_leaf': [1,10,25],\n",
    "    'randomforestclassifier__n_estimators': [100, 150, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe94a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only uncomment this line if you really want to start the GridSearch (which can take 10+ minutes)\n",
    "#clf = GridSearchCV(pipeline_rf, param_dict, scoring='balanced_accuracy')\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a88c7b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# let's check which model performed best\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[43mclf\u001b[49m\u001b[38;5;241m.\u001b[39mcv_results_)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# let's check which model performed best\n",
    "pd.DataFrame.from_dict(clf.cv_results_).sort_values(\"mean_test_score\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbf13c",
   "metadata": {},
   "source": [
    "The best parameter found by `GridSearchCV` are:\n",
    "\n",
    "```\n",
    "mean_fit_time                                                                              0.197549\n",
    "std_fit_time                                                                               0.005809\n",
    "mean_score_time                                                                            0.012872\n",
    "std_score_time                                                                             0.000222\n",
    "param_randomforestclassifier__min_samples_leaf                                                    1\n",
    "param_randomforestclassifier__n_estimators                                                      200\n",
    "param_tfidfvectorizer__max_df                                                                   0.5\n",
    "param_tfidfvectorizer__max_features                                                             500\n",
    "param_tfidfvectorizer__min_df                                                                     2\n",
    "param_tfidfvectorizer__ngram_range                                                           (1, 1)\n",
    "param_tfidfvectorizer__stop_words                                                           english\n",
    "params                                            {'randomforestclassifier__min_samples_leaf': 1...\n",
    "split0_test_score                                                                          0.613636\n",
    "split1_test_score                                                                          0.614685\n",
    "split2_test_score                                                                           0.68951\n",
    "split3_test_score                                                                          0.706643\n",
    "split4_test_score                                                                          0.683636\n",
    "mean_test_score                                                                            0.661622\n",
    "std_test_score                                                                             0.039484\n",
    "rank_test_score                                                                                   1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c55480",
   "metadata": {},
   "source": [
    "## Save the best model for later use\n",
    "Since GridSearchCV can take a lot of time, we should save the best estimator found by GridSearch for later use (so that we do not have to redo the search every single time to get the best model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa076a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# save\n",
    "joblib.dump(clf.best_estimator_, \"best_rf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2440d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# load\n",
    "rf_best = joblib.load(\"best_rf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef007b",
   "metadata": {},
   "source": [
    "Let's check the performance of our model found by GridSearch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69cba8",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b054d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# make predictions on the test set\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# create a confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbcf5184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fccd66e03a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=rf.classes_)\n",
    "\n",
    "plot_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf0ffe",
   "metadata": {},
   "source": [
    "## Precision, Recall, and F<sub>1</sub> scores for the \"1\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca4021a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257c2fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9058823529411765"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8529e69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9112426035502958"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44b7f6",
   "metadata": {},
   "source": [
    "## Precision, Recall, and F<sub>1</sub> scores for the \"0\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d68de344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837837837837838"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d254eb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055555555555556"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d42c324e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945205479452055"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561eab2",
   "metadata": {},
   "source": [
    "This looks much better! Even though the scores are still far from perfect, tuning the hyper-parameters certainly helped a great deal in increasing its overall performance (we increased the f1 score of our negative labels from 0.36 to 0.86!!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481785f",
   "metadata": {},
   "source": [
    "# Hands-On: Training a KNN classifier\n",
    "In this part, it is up to you to train your own KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d0319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
